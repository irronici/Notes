## 00 MapReduce考试复习

[toc]

#### ch1. 为什么需要并行计算

单核处理器性能提升接近极限；应用领域计算规模和复杂度的大幅提高

#### ch1. 提升计算机硬件性能的基本技术手段

提高处理器字长 ，流水线等微体系结构技术；提高集成度；提高处理器频率

#### ch1. 并行技术分类

+ 弗林：SISD, SIMD, MISD, MIMD
+ 并行类型：位级并行、指令级并行、线程级并行（数据级/任务级并行）
+ 存储访问结构：共享内存、分布共享存储体系结构、分布式内存
+ 按系统类型：多核/众核并行计算系统MC、对称多处理系统SMP、大规模并行处理MPP、集群、网格
+ 按计算特征：
+ 按并行程序设计模型/方法

#### ch1. 程序并行度评估

$$
s=\frac{1}{(1-P)+\frac{P}{N}}
$$

其中，S是加速比，P是程序可并行比例，N是处理器数目。说明：并行程序的加速程度是有限制的

#### ch2. MapReduce

MapReduce 对付大数据处理的基本思想方法是 **<u>分而治之</u>** ，并依据大数据处理的特征建立了一个包含Map 和 Reduce操作的抽象模型，
其核心思想和目的是 **<u>用 Map 和 Reduce 两个函数提供高层的并行编程抽象模型</u>**，
进一步上升到一个统一的并行计算软件构架，其主要作用和目的是 **<u>为程序员隐藏绝大多数系统层细节</u>**

#### ch2. 同步障的作用

保障等到所有的map函数做完后才进入reduce处理

#### ch2. MapReduce提供统一的构架并完成以下的主要功能

+ 任务调度
+ 数据/代码互定位
+ 出错处理
+ 分布式数据存储与文件管理
+  Combiner和Partitioner（设计目的和作用）

#### ch2. MapReduce的主要设计思想与特点*

+ 横向扩展，而非纵向扩展
+ 失效被认为是常态
+ 把处理向数据迁移
+ 顺序处理数据、避免随机访问数据
+ 为应用开发者屏蔽系统层细节
+ 平滑的可拓展性：数据扩展 和 系统规模扩展

#### ch3. MapReduce基本工作流程*

1. 将待处理任务划分为大小相同的数据块（如64MB/128MB），及其相应的用户作业程序
2. 用户作业程序提交给主节点
3. 主节点为作业程序寻找和分配可用Map节点，并传送数据与程序
4. 主节点为作业程序寻找和分配可用Reduce节点，并传送程序
5. 主节点启动每个Map节点执行程序（Map节点尽可能读取本地数据进行计算）
6. Map节点处理数据，做数据整理，并将中间结果存放在本地；通知主节点任务完成并告知结果中间结果存放位置
   + 之所以不直接丢给对应的Reduce节点是因为
     + Reduce节点可能在忙
     + 万一Reduce节点计算到一般故障了Map节点又要重新算一遍
7. Map节点全部计算完毕后启动Reduce节点，Reduce节点从主节点所掌握的中间结果位置处读取数据
8. Reduce将计算结果汇总并输出到文件

#### ch3. MapReduce数据存储

MapReduce 在数据存储方面采用多副本存储设计。

同一个数据块的多个副本存放在不同节点上加快传输速度；

可以判断网络传输是否出错；

可以保证某个DataNode 失效的情况下，不会丢失数据。

#### ch3. MapReduce失效处理

+ 主节点失效：主节点会周期性地设置检查点，一旦某个任务失效，可以从最近有效的检查点开始重新执行，避免从头开始计算的时间浪费。
+ 工作节点失效：主节点会周期性地给工作节点发送心跳检测，若工作节点没有回应，则认为该工作节点失效，主节点将终止该工作节点的任务并将其任务重新调度到其他工作节点上执行。

####  ch3. MapReduce性能优化

+ 带宽优化：增加Combiner类，减少网络通信带宽。

+ 计算优化：把一个计算任务同时让多个 Map节点做，取最快完成者的计算结果。
+ 数据相关性问题：通过Partition类进行数据分区，减少传输到Reduce节点上的数据相关性

#### ch3. Google GFS的基本设计原则

+ 廉价本地磁盘分布存储
+ 多数据自动备份解决可靠性
+ 为上层的MapReduce计算框架提供支撑

#### ch3. GFS基本架构

+ GFS Master：管理元数据
+ GFS ChunkServer：保存实际数据

+ 数据访问过程

1. 程序运行前，数据已经存储在GFS文件系统中。程序实行时 应用程序告诉 GFS Server 要访问的文件名/索引是什么
2. GFS Server根据文件名/索引，查找其具体在哪些ChunkServer上，并向应用程序返回位置信息
3. 应用程序根据返回的Chunk位置信息，直接访问相应的Chunk Server直接读取数据进行计算处理

+ 特点：

  + 应用程序访问具体数据时不需要经过GFS Master，避免Master成为访问瓶颈

  + 一个大数据会存储在不同ChunkServer中，应用程序可以实现并发访问

#### ch3. Hadoop MapReduce基本架构

+ JobTracker=Master：hadoop 主控节点，负责调度管理作业中的任务
+ TaskTracker=worker：作为从节点，负责执行JobTracker分来的任务
+ NameNode=MasterServer：存储和管理分布式系统的元数据
+ DataNode=ChunkServer：实际存储大规模数据的从节点，存储实际数据

#### ch3. Combiner &  Partiotioner

执行时间都是：Map 节点完成计算之后，输出中间结果之前

+ combiner：合并相同Key的键值对，减少数据通信开销
+ partitioner：数据分区，消除数据传入 Reduce 后带来的不必要的相关性

#### ch3. HDFS可靠性与出错恢复

+ DataNode节点的心跳检测：NameNode不断检测DataNode是否有效；若失效，则寻找新的节点替代，将失效节点数据重新分布
+ 集群负载均衡
+ 数据一致性：校验和
+ 主节点元数据失效
  + Multiple FsImage and EditLog
  + Checkpoint

#### ch6. HBase shell 操作

+ 建表Create：`create '表名','RowKey','列族1'，...,'列族n'` 
+ 插入put：`put 'students','001','Description:Name','Li Lei'` 
+ 显示描述表信息Describe：`describe students`
+ 扫描数据（显示表内容） `scan students,{COLUMNS='Courses:'}` 
+ Disable：禁用写，比如修改表的样式的时候可以用（对应enable）
  + disable：在zookeeper中做记录，并将表的全部region下线

#### ch6. Hive数据模型

+ hive数据模型由数据表组成
+ 元素局存储：Metastore

#### ch7. 用户自定义数据类型
+ 需要实现Writable接口
+ 作为key或者需要比较大小时则需要实现WritableComparable接口

#### ch7. 全局参数/数据文件的传递

+ 使用 Configuration 完成全局参数在全局计算节点上的传递和共享。
+ 使用 DistributedCache 进行小数据量文件的全局传递

#### ch10. Spark的技术特点

+ 基于内存计算的弹性分布式数据集(RDD)

+ 灵活的计算流图(DAG)
+ 覆盖多种计算模式